(25:58) ground Tru response now that is a classical way to do it however um given the complexity of tasks LMS are used then you might not always have such a ground truth and even when you do on certain tasks uh you can for example summarization um there's multiple ways to write a summary and all of them might be valid but the ground troot would be just one such instance so it would not be a valid way to um evaluate such cases as well so what we can also do is use llm as autter rators where you uh where you kind of have an llm evaluate an

(26:32) llm and uh and evaluate how good the response of the uh generated by the uh the model was and you can do this in in a point Vice fashion in a pairwise fashion fa you can just say okay here's the response here's my prompt how well on a score of one to five do I does this response score and why is it why is that the case or in a paer wise fashion you compare to resp responses and say okay um tell me uh for this prompt which one is the better response and it says okay response the left one is better because

(27:07) uh whatever reasoning and we actually have that available so you can use that right away and our Vortex Suite of uh through our Vortex AI generative AI evaluation service you can try uh llm uh based aerator evaluation as well as um computational metrics like Rouge and blow which use a reference point can try that out today absolutely and I've I've also seen some pretty impressive open- Source libraries uh doing autora rating and evaluations as well um have been really delighted with prompt Fu which also has

(27:43) the the Gemini API support uh and and some of the other uh some of the other offerings so great to know that there are vertex AI options as well as open source libraries um to to go about doing these evaluations whether they're human rate or Auto evaluated very cool excellent next question from Red 365 um Can someone please explain why for the First Chain of Thought prompt it's also explaining step by step instead of answering that directly Lee I see you nodding um do you want to go ahead and take this question yeah yeah I

(28:21) can uh talk a little bit about that because I had similar uh yeah examples in in the white paper that I wrote and um so first of all for the folks on the call like chain of thoughts Chain of Thought of C prompting that's a prompting technique where you you you try to let the llm generate intermediate steps and uh yeah typically you can do that by providing examples on how to reason and then you don't take the example as what's in the Cod laab you try to come up with another example that which has similar reasoning techniques

(28:56) and uh yeah then you see it will then showcase the steps now this particular question and and thank you everyone for yeah participating in the collab uh I saw some people saying like hey because in the question you had to first type in an example where we did do not use cod uh prompting and then afterwards we will show an example an example where we use Chain of Thought prompting so you could see the difference but the problem was that some people already saw the the the intermediate steps in the first uh first

(29:28) example while it shouldn't it's very difficult nowadays with models that get so good you know our our models are so good like we cannot showcase these flaws anymore but uh you might be able to uh reproduce it by either like often maybe uh just resubmitting the the question uh it might help also just to change the the top K top P or temperature so you get more variance in the in the outputs and uh I saw also in the in the chat some fol saying that uh switching to the older Gemini models will showcase how

(30:02) you can uh showcase the flaw and then later you can fix it with J of thoughts so that's cool stuff very cool I I love uh I love kind of the detailed description of uh of Chain of Thought in and of itself and then also how you can see it expressed as model outputs this is very very cool um and personally I I found especially for things like uh like coding tasks chain of thought prompting or uh or asking the model to explain its reasoning has been very very powerful and has usually led to significantly better results yeah so this is this is

(30:39) very cool yeah um the next question uh from usang Kung is um is something like inam mode um a in a fine tune model designed to return enum values um and Daniel uh it's great to see you by the way welcome back uh uh for folks on the call Daniel and I used to work together at Deep Mind um and now uh now I believe you have started your own company uh uh or you're still in stealth mode for your company so I won't I won't give spoilers um but it's great to have you H would you like to answer this

(31:19) question yeah sure yeah nice to see you as well Paige and yeah thanks for having having me um yeah and and I think that uh in in terms of enam mode I mean it it it very much depends on on what you're trying to do so if you're fine-tuning your model um and you want it to Output enums this depends a lot on how you structure your data so for example if you have three different enum values that you'd like to Output um you would structure your inputs as the question or task that you want to provide to your

(31:52) llm and then the output would be one of the enum values whichever one is most relevant to the question or task um that you asked the llm to provide a output on um and uh so you can find tune llms like that and generate your prepare your data sets with these inputs as being the task or questions and the outputs being the enums um and also you know llms are also sometimes very good out of the box in dealing with enums so you can also say to an llm something like these are the different types of classifications that

(32:24) you can choose or enums that you can choose um choose the appropriate one for the question that we're asking so suggestion would be to also try it zero shot and if not you can create These Fine tuned data sets um and I think there was a question about uh related to notebook uh llm that was uh along these lines page oh yes I I I believe the the question that you were referring to was um from gavas um which is all about uh all about notebook LM how it was built how it was uh how it was created I've really really

(33:02) loved experimenting with it as well as the illuminate kind of automatic podcast generator for any arbitrary data types um the uh I for Noak LM interestingly enough um and this was shared by Josh Woodward at a recent event um it's not using a fine-tuned version of Gemini um it's just using Gemini 1.5 Pro and 1.
