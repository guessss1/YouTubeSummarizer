(06:30) a great question I think the two that are top of mind right now um about two weeks ago we landed grounding with Google search which is really exciting so I think this will surely be a topic of conversation over the next five days but llms and hallucination and grounding and rag uh grounding with Google search is is a way to sort of tap into the the search index that Google has and bring some of that information to ground answers rather ground questions uh that that users of of LMS have so super super interesting there's yeah if you just

(07:02) Google search grounding with Google uh you'll you'll find some some of the links across the developer side the Enterprise side um so excited about that happy to talk more about it the other thing is Friday we landed uh open AI compatibility which I'm super excited so for developers who are already using the open Ai sdks and libraries um you can now try out the Gemini models using those sdks and libraries by only changing like three lines of code or something like that so um excited to to sort of reduce the friction for

(07:32) developers who are excited about using Gemini and yeah hopefully we'll we'll hear a bunch of great feedback about that launch as well excellent I personally have been really really jazzed for uh for the open AI API compatibility um it's been really really straightforward to convert notebooks that might have been preferring the open AI apis to just using Gemini um and to be able to compare and contrast between the two um so those are those are definitely two exciting things that have come out um and I encourage everyone to take a

(08:02) look at the uh at the open AI compatibility and then also the search grounding features um within AI Studio I think it's especially cool that you can use search grounding with even some of our smaller models uh like Gemini 1.5 Flash and Gemini 1.5 flab um I've been loving both of those for my projects especially things um requiring uh you know code execution or are super fast inference um uh tell me tell me a little bit about those two Flash series of models um and how you can do so much so quickly um with a very small cost

(08:38) footprint yeah so we we landed um after a bunch of work internally we landed The Flash AP model which is the smallest uh sort of Gemini hosted model that that exists um 8 billion parameter model and really pushes sort of the envelope of you know compute intelligence per dollar I think we've seen a bunch of those tweets page you and I have been ones putting those out but it's like two three cents per million tokens if you using cash tokens it's one cent per million tokens so just like an absolute an absolute crazy amount of

(09:14) intelligence that you can get for um for a couple of cents and I think the the sort of interesting thread of why those small models are interesting to me is because a lot of the you know Frontier use cases of AI are actually founded by uh by cost and token cost so like there's a lot of things like the developers actually inherently have a disincentive to build because it's like you you are paying the more AI the more AI you build into something the more you pay um and I think flash AP is like a great example of sort of pushing the

(09:48) frontier of trying to like remove that barrier so that developers can actually just build the things that they're excited about um and not need to sort of worry about you know the incremental amount of costs that they take on yeah amazing um and then one last question and then we're going to we're going to bring in some more folks to to discuss uh especially the production applications of of generative AI um you know deep Minds multimodal models uh I'm thinking particularly of imagine and vo for video

(10:16) generation Lia for music generation they unlock some really interesting new applications especially when coupled with the Gemini models um what has been your favorite application for for these kind of um multimodal output scenarios um and uh and um how do you think about coupling those with a gem apis yeah that's a really good question I I think the it is so hard to create um or rather I think text as sort of like an output mechanism for models I think like you know developers have found the interesting things to do with
